{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "from pyro.contrib.examples.bart import load_bart_od\n",
    "from pyro.contrib.forecast import ForecastingModel, Forecaster, backtest, eval_crps\n",
    "from pyro.infer.reparam import LocScaleReparam, StableReparam\n",
    "from pyro.ops.tensor_utils import periodic_cumsum, periodic_repeat, periodic_features\n",
    "from pyro.ops.stats import quantile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "print( pyro.__version__)\n",
    "assert pyro.__version__.startswith('1.5')\n",
    "pyro.enable_validation(True)\n",
    "pyro.set_rng_seed(20200221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_bart_od()\n",
    "print(dataset.keys())\n",
    "print(dataset[\"counts\"].shape)\n",
    "print(\" \".join(dataset[\"stations\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T, O, D = dataset[\"counts\"].shape\n",
    "data = dataset[\"counts\"][:T // (24 * 7) * 24 * 7].reshape(T // (24 * 7), -1).sum(-1).log()\n",
    "data = data.unsqueeze(-1)\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.plot(data)\n",
    "plt.title(\"Total weekly ridership\")\n",
    "plt.ylabel(\"log(# rides)\")\n",
    "plt.xlabel(\"Week after 2011-01-01\")\n",
    "plt.xlim(0, len(data));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need some boilerplate to create a class and define a .model() method.\n",
    "class Model1(ForecastingModel):\n",
    "    # We then implement the .model() method. Since this is a generative model, it shouldn't\n",
    "    # look at data; however it is convenient to see the shape of data we're supposed to\n",
    "    # generate, so this inputs a zeros_like(data) tensor instead of the actual data.\n",
    "    def model(self, zero_data, covariates):\n",
    "        data_dim = zero_data.size(-1)  # Should be 1 in this univariate tutorial.\n",
    "        feature_dim = covariates.size(-1)\n",
    "\n",
    "        # The first part of the model is a probabilistic program to create a prediction.\n",
    "        # We use the zero_data as a template for the shape of the prediction.\n",
    "        bias = pyro.sample(\"bias\", dist.Normal(0, 10).expand([data_dim]).to_event(1))\n",
    "        weight = pyro.sample(\"weight\", dist.Normal(0, 0.1).expand([feature_dim]).to_event(1))\n",
    "        prediction = bias + (weight * covariates).sum(-1, keepdim=True)\n",
    "        # The prediction should have the same shape as zero_data (duration, obs_dim),\n",
    "        # but may have additional sample dimensions on the left.\n",
    "        assert prediction.shape[-2:] == zero_data.shape\n",
    "\n",
    "        # The next part of the model creates a likelihood or noise distribution.\n",
    "        # Again we'll be Bayesian and write this as a probabilistic program with\n",
    "        # priors over parameters.\n",
    "        noise_scale = pyro.sample(\"noise_scale\", dist.LogNormal(-5, 5).expand([1]).to_event(1))\n",
    "        noise_dist = dist.Normal(0, noise_scale)\n",
    "\n",
    "        # The final step is to call the .predict() method.\n",
    "        self.predict(noise_dist, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T0 = 0              # begining\n",
    "T2 = data.size(-2)  # end\n",
    "T1 = T2 - 52        # train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pyro.set_rng_seed(1)\n",
    "pyro.clear_param_store()\n",
    "time = torch.arange(float(T2)) / 365\n",
    "covariates = torch.stack([time], dim=-1)\n",
    "forecaster = Forecaster(Model1(), data[:T1], covariates[:T1], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = forecaster(data[:T1], covariates, num_samples=1000)\n",
    "p10, p50, p90 = quantile(samples, (0.1, 0.5, 0.9)).squeeze(-1)\n",
    "crps = eval_crps(samples, data[T1:])\n",
    "print(samples.shape, p10.shape)\n",
    "\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.fill_between(torch.arange(T1, T2), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(T1, T2), p50, 'r-', label='forecast')\n",
    "plt.plot(data, 'k-', label='truth')\n",
    "plt.title(\"Total weekly ridership (CRPS = {:0.3g})\".format(crps))\n",
    "plt.ylabel(\"log(# rides)\")\n",
    "plt.xlabel(\"Week after 2011-01-01\")\n",
    "plt.xlim(0, None)\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 3))\n",
    "plt.fill_between(torch.arange(T1, T2), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(T1, T2), p50, 'r-', label='forecast')\n",
    "plt.plot(torch.arange(T1, T2), data[T1:], 'k-', label='truth')\n",
    "plt.title(\"Total weekly ridership (CRPS = {:0.3g})\".format(crps))\n",
    "plt.ylabel(\"log(# rides)\")\n",
    "plt.xlabel(\"Week after 2011-01-01\")\n",
    "plt.xlim(T1, None)\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pyro.set_rng_seed(1)\n",
    "pyro.clear_param_store()\n",
    "time = torch.arange(float(T2)) / 365\n",
    "covariates = torch.cat([time.unsqueeze(-1),\n",
    "                        periodic_features(T2, 365.25 / 7)], dim=-1)\n",
    "forecaster = Forecaster(Model1(), data[:T1], covariates[:T1], learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = forecaster(data[:T1], covariates, num_samples=1000)\n",
    "p10, p50, p90 = quantile(samples, (0.1, 0.5, 0.9)).squeeze(-1)\n",
    "crps = eval_crps(samples, data[T1:])\n",
    "\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.fill_between(torch.arange(T1, T2), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(T1, T2), p50, 'r-', label='forecast')\n",
    "plt.plot(data, 'k-', label='truth')\n",
    "plt.title(\"Total weekly ridership (CRPS = {:0.3g})\".format(crps))\n",
    "plt.ylabel(\"log(# rides)\")\n",
    "plt.xlabel(\"Week after 2011-01-01\")\n",
    "plt.xlim(0, None)\n",
    "plt.legend(loc=\"best\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 3))\n",
    "plt.fill_between(torch.arange(T1, T2), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(T1, T2), p50, 'r-', label='forecast')\n",
    "plt.plot(torch.arange(T1, T2), data[T1:], 'k-', label='truth')\n",
    "plt.title(\"Total weekly ridership (CRPS = {:0.3g})\".format(crps))\n",
    "plt.ylabel(\"log(# rides)\")\n",
    "plt.xlabel(\"Week after 2011-01-01\")\n",
    "plt.xlim(T1, None)\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(ForecastingModel):\n",
    "    def model(self, zero_data, covariates):\n",
    "        data_dim = zero_data.size(-1)\n",
    "        feature_dim = covariates.size(-1)\n",
    "        bias = pyro.sample(\"bias\", dist.Normal(0, 10).expand([data_dim]).to_event(1))\n",
    "        weight = pyro.sample(\"weight\", dist.Normal(0, 0.1).expand([feature_dim]).to_event(1))\n",
    "\n",
    "        # We'll sample a time-global scale parameter outside the time plate,\n",
    "        # then time-local iid noise inside the time plate.\n",
    "        drift_scale = pyro.sample(\"drift_scale\",\n",
    "                                  dist.LogNormal(-20, 5).expand([1]).to_event(1))\n",
    "        with self.time_plate:\n",
    "            # We'll use a reparameterizer to improve variational fit. The model would still be\n",
    "            # correct if you removed this context manager, but the fit appears to be worse.\n",
    "            with poutine.reparam(config={\"drift\": LocScaleReparam()}):\n",
    "                drift = pyro.sample(\"drift\", dist.Normal(zero_data, drift_scale).to_event(1))\n",
    "\n",
    "        # After we sample the iid \"drift\" noise we can combine it in any time-dependent way.\n",
    "        # It is important to keep everything inside the plate independent and apply dependent\n",
    "        # transforms outside the plate.\n",
    "        motion = drift.cumsum(-2)  # A Brownian motion.\n",
    "\n",
    "        # The prediction now includes three terms.\n",
    "        prediction = motion + bias + (weight * covariates).sum(-1, keepdim=True)\n",
    "        assert prediction.shape[-2:] == zero_data.shape\n",
    "\n",
    "        # Construct the noise distribution and predict.\n",
    "        noise_scale = pyro.sample(\"noise_scale\", dist.LogNormal(-5, 5).expand([1]).to_event(1))\n",
    "        noise_dist = dist.Normal(0, noise_scale)\n",
    "        self.predict(noise_dist, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pyro.set_rng_seed(1)\n",
    "pyro.clear_param_store()\n",
    "time = torch.arange(float(T2)) / 365\n",
    "covariates = periodic_features(T2, 365.25 / 7)\n",
    "forecaster = Forecaster(Model2(), data[:T1], covariates[:T1], learning_rate=0.1,\n",
    "                        time_reparam=\"dct\",\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = forecaster(data[:T1], covariates, num_samples=1000)\n",
    "p10, p50, p90 = quantile(samples, (0.1, 0.5, 0.9)).squeeze(-1)\n",
    "crps = eval_crps(samples, data[T1:])\n",
    "\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.fill_between(torch.arange(T1, T2), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(T1, T2), p50, 'r-', label='forecast')\n",
    "plt.plot(data, 'k-', label='truth')\n",
    "plt.title(\"Total weekly ridership (CRPS = {:0.3g})\".format(crps))\n",
    "plt.ylabel(\"log(# rides)\")\n",
    "plt.xlabel(\"Week after 2011-01-01\")\n",
    "plt.xlim(0, None)\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model3(ForecastingModel):\n",
    "    def model(self, zero_data, covariates):\n",
    "        data_dim = zero_data.size(-1)\n",
    "        feature_dim = covariates.size(-1)\n",
    "        bias = pyro.sample(\"bias\", dist.Normal(0, 10).expand([data_dim]).to_event(1))\n",
    "        weight = pyro.sample(\"weight\", dist.Normal(0, 0.1).expand([feature_dim]).to_event(1))\n",
    "\n",
    "        drift_scale = pyro.sample(\"drift_scale\", dist.LogNormal(-20, 5).expand([1]).to_event(1))\n",
    "        with self.time_plate:\n",
    "            with poutine.reparam(config={\"drift\": LocScaleReparam()}):\n",
    "                drift = pyro.sample(\"drift\", dist.Normal(zero_data, drift_scale).to_event(1))\n",
    "        motion = drift.cumsum(-2)  # A Brownian motion.\n",
    "\n",
    "        prediction = motion + bias + (weight * covariates).sum(-1, keepdim=True)\n",
    "        assert prediction.shape[-2:] == zero_data.shape\n",
    "\n",
    "        # The next part of the model creates a likelihood or noise distribution.\n",
    "        # Again we'll be Bayesian and write this as a probabilistic program with\n",
    "        # priors over parameters.\n",
    "        stability = pyro.sample(\"noise_stability\", dist.Uniform(1, 2).expand([1]).to_event(1))\n",
    "        skew = pyro.sample(\"noise_skew\", dist.Uniform(-1, 1).expand([1]).to_event(1))\n",
    "        scale = pyro.sample(\"noise_scale\", dist.LogNormal(-5, 5).expand([1]).to_event(1))\n",
    "        noise_dist = dist.Stable(stability, skew, scale)\n",
    "\n",
    "        # We need to use a reparameterizer to handle the Stable distribution.\n",
    "        # Note \"residual\" is the name of Pyro's internal sample site in self.predict().\n",
    "        with poutine.reparam(config={\"residual\": StableReparam()}):\n",
    "            self.predict(noise_dist, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pyro.set_rng_seed(2)\n",
    "pyro.clear_param_store()\n",
    "time = torch.arange(float(T2)) / 365\n",
    "covariates = periodic_features(T2, 365.25 / 7)\n",
    "forecaster = Forecaster(Model3(), data[:T1], covariates[:T1], learning_rate=0.1,\n",
    "                        time_reparam=\"dct\")\n",
    "for name, value in forecaster.guide.median().items():\n",
    "    if value.numel() == 1:\n",
    "        print(\"{} = {:0.4g}\".format(name, value.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = forecaster(data[:T1], covariates, num_samples=1000)\n",
    "p10, p50, p90 = quantile(samples, (0.1, 0.5, 0.9)).squeeze(-1)\n",
    "crps = eval_crps(samples, data[T1:])\n",
    "\n",
    "plt.figure(figsize=(9, 3))\n",
    "plt.fill_between(torch.arange(T1, T2), p10, p90, color=\"red\", alpha=0.3)\n",
    "plt.plot(torch.arange(T1, T2), p50, 'r-', label='forecast')\n",
    "plt.plot(data, 'k-', label='truth')\n",
    "plt.title(\"Total weekly ridership (CRPS = {:0.3g})\".format(crps))\n",
    "plt.ylabel(\"log(# rides)\")\n",
    "plt.xlabel(\"Week after 2011-01-01\")\n",
    "plt.xlim(0, None)\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pyro.set_rng_seed(1)\n",
    "pyro.clear_param_store()\n",
    "windows2 = backtest(data, covariates, Model2,\n",
    "                    min_train_window=104, test_window=52, stride=26,\n",
    "                    forecaster_options={\"learning_rate\": 0.1, \"time_reparam\": \"dct\",\n",
    "                                        \"log_every\": 1000, \"warm_start\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "pyro.set_rng_seed(1)\n",
    "pyro.clear_param_store()\n",
    "windows3 = backtest(data, covariates, Model3,\n",
    "                    min_train_window=104, test_window=52, stride=26,\n",
    "                    forecaster_options={\"learning_rate\": 0.1, \"time_reparam\": \"dct\",\n",
    "                                        \"log_every\": 1000, \"warm_start\": True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, figsize=(8, 6), sharex=True)\n",
    "axes[0].set_title(\"Gaussian versus Stable accuracy over {} windows\".format(len(windows2)))\n",
    "axes[0].plot([w[\"crps\"] for w in windows2], \"b<\", label=\"Gaussian\")\n",
    "axes[0].plot([w[\"crps\"] for w in windows3], \"r>\", label=\"Stable\")\n",
    "axes[0].set_ylabel(\"CRPS\")\n",
    "axes[1].plot([w[\"mae\"] for w in windows2], \"b<\", label=\"Gaussian\")\n",
    "axes[1].plot([w[\"mae\"] for w in windows3], \"r>\", label=\"Stable\")\n",
    "axes[1].set_ylabel(\"MAE\")\n",
    "axes[2].plot([w[\"rmse\"] for w in windows2], \"b<\", label=\"Gaussian\")\n",
    "axes[2].plot([w[\"rmse\"] for w in windows3], \"r>\", label=\"Stable\")\n",
    "axes[2].set_ylabel(\"RMSE\")\n",
    "axes[0].legend(loc=\"best\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
